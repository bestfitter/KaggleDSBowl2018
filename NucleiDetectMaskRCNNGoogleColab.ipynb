{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DS2018_killthekitten_V9.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "OdKDP9eymEYp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# MaskRCNN for Nuclei Detection on Google Colab (LB=0.382)\n",
        "\n",
        "This kernel implements the following:\n",
        "\n",
        "1.   MaskRCNN implementation at https://github.com/killthekitten/kaggle-ds-bowl-2018-baseline#kaggle-ds-bowl-2018 in Jupyter Notebook form.\n",
        "> - No change in code, only changed modules train.py and inference.py into procedures so they can be run within this notebook and take parameters\n",
        "> - Using this code made 6 submissions after every 5 epochs going upto 35 epochs (5, 10, 15, 20, 25, 30, 35). Scores increased on LB until 20 epochs, then went down (probably overfitting). Max LB score at 20 epochs = 0.382\n",
        "\n",
        "2.   Be able to run this notebook in Google Collaboratory (https://colab.research.google.com/) and utilize the free GPU support. (Takes an average 10 minutes to run 1 epoch with GPU)\n",
        "> - Loads all the competition data from Kaggle into Google Colab (the virtual environment allocated to the user)  \n",
        "> - Loads the model weights as required by the item 1 above into Google Colab\n",
        "> - Loads the code from github for item 1 implementation\n",
        "> - Can make competition submissions to Kaggle site directly from Google colab\n",
        "> - After every 5 epochs during RCNN training uploads h5 weights file to your Google drive\n",
        "\n",
        "#### Note: The ability to periodically save the trainined weights (e.g. after every 5 epochs) in Google Drive (or locally) is desirable because: a) Google Colab session expires after 12 hrs and resets(deletes) all imported files and data. The runtime (i.e. program and datastore) is also reset, and b)if your internet connection is interupted the runtime at Google Colab is reset - at least thats what I have experienced."
      ]
    },
    {
      "metadata": {
        "id": "z-xlh9q8hOPh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 1 of 6: Get access to Kaggle site\n",
        "In order to access Kaggle competition data from Google Colab, Kaggle json authentication is needed which requires the user specific 'kaggle.json' file from Kaggle site to be downloaded to your machine. \n",
        "\n",
        "- Go to https://www.kaggle.com/{your_kaggle_user_id}/account under 'API', choose 'Create New API Token'. This will download the 'kaggle.json' file to your machine. Note down the folder in which the file is downloaded (usually the 'Download' folder in Windows). \n",
        "\n",
        "- After the 'kaggle.json' file is downloaded to your computer, run the cell below.\n",
        "- A 'Choose Files' button will appear below the cell. Click it and it will open a files browser window\n",
        "- Select the 'kaggle.json' file to upload it to Google Colab."
      ]
    },
    {
      "metadata": {
        "id": "897gIDqbTAHf",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "aa7f992e-a549-48cd-db9d-6ad491b5b666",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523332529090,
          "user_tz": 300,
          "elapsed": 28055,
          "user": {
            "displayName": "Aftab Khan",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "115745872669652090393"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import io, os\n",
        "\n",
        "# The following line 'upload()' method will open a folder browser window for you to \n",
        "# select and choose the 'kaggle.json' file on your computer\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))\n",
        "\n",
        "# Make the folder '.kaggle' on the Google Colab VM\n",
        "filename = \"/content/.kaggle/kaggle.json\"\n",
        "os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
        "\n",
        "# Move the 'kaggle.json' file to the '.kaggle' folder\n",
        "!mv kaggle.json /content/.kaggle/\n",
        "\n",
        "# change the permissions of the 'kaggle.json' file to make it secure\n",
        "!chmod 600 /content/.kaggle/kaggle.json\n",
        "#!ls -la /content/.kaggle/\n",
        "\n",
        "# Check if Kaggle site can be accessed\n",
        "# install the 'kaggle' module. The '-q' is for quite mode.\n",
        "!pip install -q kaggle\n",
        "\n",
        "# List all the competitions currently on the Kaggle site.\n",
        "# Note: All Kaggle API commands can be found at: https://github.com/Kaggle/kaggle-api\n",
        "!kaggle competitions list"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a52b689f-1fde-4f41-a14d-5866da41ee94\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-a52b689f-1fde-4f41-a14d-5866da41ee94\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "User uploaded file \"kaggle.json\" with length 62 bytes\n",
            "ref                                             deadline             category            reward  teamCount  userHasEntered  \n",
            "----------------------------------------------  -------------------  ---------------  ---------  ---------  --------------  \n",
            "imagenet-object-detection-challenge             2029-12-31 07:00:00  Research         Knowledge          0           False  \n",
            "imagenet-object-detection-from-video-challenge  2029-12-31 07:00:00  Research         Knowledge          0           False  \n",
            "imagenet-object-localization-challenge          2029-12-31 07:00:00  Research         Knowledge          6           False  \n",
            "titanic                                         2020-04-07 00:00:00  Getting Started  Knowledge      10745            True  \n",
            "house-prices-advanced-regression-techniques     2020-03-01 23:59:00  Getting Started  Knowledge       4554           False  \n",
            "digit-recognizer                                2020-01-07 00:00:00  Getting Started  Knowledge       2124           False  \n",
            "competitive-data-science-predict-future-sales   2019-01-01 23:59:00  Playground           Kudos        236           False  \n",
            "freesound-audio-tagging                         2018-07-31 23:59:00  Research         Knowledge         40           False  \n",
            "whale-categorization-playground                 2018-07-09 23:59:00  Playground           Kudos        160           False  \n",
            "cvpr-2018-autonomous-driving                    2018-06-11 23:59:00  Research            $2,500          8           False  \n",
            "inaturalist-2018                                2018-06-04 23:59:00  Research             Kudos         27           False  \n",
            "imaterialist-challenge-fashion-2018             2018-05-30 23:59:00  Research            $2,500         18           False  \n",
            "imaterialist-challenge-furniture-2018           2018-05-30 23:59:00  Research            $2,500        168           False  \n",
            "landmark-retrieval-challenge                    2018-05-22 23:59:00  Research            $2,500        110           False  \n",
            "landmark-recognition-challenge                  2018-05-22 23:59:00  Research            $2,500        220           False  \n",
            "talkingdata-adtracking-fraud-detection          2018-05-07 23:59:00  Featured           $25,000       2496           False  \n",
            "donorschoose-application-screening              2018-04-25 23:59:00  Playground            Swag        437            True  \n",
            "data-science-bowl-2018                          2018-04-16 23:59:00  Featured          $100,000       3543            True  \n",
            "mens-machine-learning-competition-2018          2018-04-02 23:59:00  Featured           $50,000        934           False  \n",
            "womens-machine-learning-competition-2018        2018-04-01 23:59:00  Featured           $50,000        505           False  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "c7rxiRwEYpYx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 2 of 6: Get all the code and data \n",
        "\n",
        "#### (the cell below takes about 25 seconds on Google Colab)\n",
        "The steps to get code and data are taken from here:\n",
        "\n",
        "https://github.com/killthekitten/kaggle-ds-bowl-2018-baseline#kaggle-ds-bowl-2018\n",
        "\n",
        "1.   First, you have to download the train masks. Thanks @lopuhin for bringing all the fixes to one place. You might want to do it outside of this repo to be able to pull changes later and use symlinks:\n",
        "> git clone https://github.com/lopuhin/kaggle-dsbowl-2018-dataset-fixes ../kaggle-dsbowl-2018-dataset-fixes\n",
        "> ln -s ../kaggle-dsbowl-2018-dataset-fixes/stage1_train stage1_train\n",
        "\n",
        "2.   Download the rest of the official dataset and unzip it to the repo:\n",
        "> unzip ~/Downloads/stage1_test.zip -d stage1_test\n",
        "> unzip ~/Downloads/stage1_train_labels.csv.zip -d .\n",
        "> unzip ~/Downloads/stage1_sample_submission.csv.zip -d .\n",
        "\n",
        "3. Install pycocotools and COCO pretrained weights (mask_rcnn_coco.h5). General idea is described here. Keep in mind, to install pycocotools properly, it's better to run make install instead of make.\n",
        "> https://github.com/matterport/Mask_RCNN/releases/download/v2.0/mask_rcnn_coco.h5\n",
        "\n",
        "4. Download the repo:\n",
        "> https://github.com/killthekitten/kaggle-ds-bowl-2018-baseline.git"
      ]
    },
    {
      "metadata": {
        "id": "LuMD6Rbwj20m",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 3918
        },
        "outputId": "a036f08a-ab45-478f-fbd7-2e72ec2820ec",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523332864183,
          "user_tz": 300,
          "elapsed": 67023,
          "user": {
            "displayName": "Aftab Khan",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "115745872669652090393"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#### Get all DS2018 data AND RCNN code ####\n",
        "!git clone https://github.com/lopuhin/kaggle-dsbowl-2018-dataset-fixes ../kaggle-dsbowl-2018-dataset-fixes\n",
        "!ln -s ../kaggle-dsbowl-2018-dataset-fixes/stage1_train stage1_train\n",
        "#!ls -l stage1_train\n",
        "\n",
        "!mkdir Downloads\n",
        "# kaggle competitions download [-h] [-c COMPETITION] [-f FILE] [-p PATH]\n",
        "#!kaggle competitions files -c data-science-bowl-2018\n",
        "!kaggle competitions download -c data-science-bowl-2018 -f stage1_sample_submission.csv.zip -p ~/Downloads/\n",
        "!kaggle competitions download -c data-science-bowl-2018 -f stage1_test.zip -p ~/Downloads/\n",
        "!kaggle competitions download -c data-science-bowl-2018 -f stage1_train_labels.csv.zip -p ~/Downloads/\n",
        "\n",
        "## Unzip the data files\n",
        "!unzip ~/Downloads/stage1_sample_submission.csv.zip -d .\n",
        "!unzip ~/Downloads/stage1_test.zip -d stage1_test\n",
        "!unzip ~/Downloads/stage1_train_labels.csv.zip -d .\n",
        "\n",
        "### Get COCO weights\n",
        "!wget https://github.com/matterport/Mask_RCNN/releases/download/v2.0/mask_rcnn_coco.h5\n",
        "\n",
        "### Get RCNN code and copy all the '.py' files to the working directory\n",
        "!git clone https://github.com/killthekitten/kaggle-ds-bowl-2018-baseline.git\n",
        "!cp kaggle-ds-bowl-2018-baseline/*.py .\n",
        "\n",
        "# Install pycocotools\n",
        "!pip install git+https://github.com/waleedka/cocoapi.git#egg=pycocotools&subdirectory=PythonAPI\n",
        "  "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into '../kaggle-dsbowl-2018-dataset-fixes'...\n",
            "remote: Counting objects: 33416, done.\u001b[K\n",
            "remote: Compressing objects: 100% (21775/21775), done.\u001b[K\n",
            "remote: Total 33416 (delta 11656), reused 33400 (delta 11640), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (33416/33416), 70.88 MiB | 1.78 MiB/s, done.\n",
            "Resolving deltas: 100% (11656/11656), done.\n",
            "stage1_sample_submission.csv.zip: Downloaded 3KB of 3KB\n",
            "stage1_test.zip: Downloaded 9MB of 9MB\n",
            "stage1_train_labels.csv.zip: Downloaded 3MB of 3MB\n",
            "Archive:  /content/Downloads/stage1_sample_submission.csv.zip\n",
            "  inflating: ./stage1_sample_submission.csv  \n",
            "Archive:  /content/Downloads/stage1_test.zip\n",
            "   creating: stage1_test/0114f484a16c152baa2d82fdd43740880a762c93f436c8988ac461c5c9dbe7d5/\n",
            "   creating: stage1_test/0999dab07b11bc85fb8464fc36c947fbd8b5d6ec49817361cb780659ca805eac/\n",
            "   creating: stage1_test/0a849e0eb15faa8a6d7329c3dd66aabe9a294cccb52ed30a90c8ca99092ae732/\n",
            "   creating: stage1_test/0e132f71c8b4875c3c2dd7a22997468a3e842b46aa9bd47cf7b0e8b7d63f0925/\n",
            "   creating: stage1_test/0ed3555a4bd48046d3b63d8baf03a5aa97e523aa483aaa07459e7afa39fb96c6/\n",
            "   creating: stage1_test/0f1f896d9ae5a04752d3239c690402c022db4d72c0d2c087d73380896f72c466/\n",
            "   creating: stage1_test/1747f62148a919c8feb6d607faeebdf504b5e2ad42b6b1710b1189c37ebcdb2c/\n",
            "   creating: stage1_test/17b9bf4356db24967c4677b8376ac38f826de73a88b93a8d73a8b452e399cdff/\n",
            "   creating: stage1_test/1879f4f4f05e2bada0ffeb46c128b8df7a79b14c84f38c3e216a69653495153b/\n",
            "   creating: stage1_test/191b2b2205f2f5cc9da04702c5d422bc249faf8bca1107af792da63cccfba829/\n",
            "   creating: stage1_test/1962d0c5faf3e85cda80e0578e0cb7aca50826d781620e5c1c4cc586bc69f81a/\n",
            "   creating: stage1_test/1cdbfee1951356e7b0a215073828695fe1ead5f8b1add119b6645d2fdc8d844e/\n",
            "   creating: stage1_test/1d9eacb3161f1e2b45550389ecf7c535c7199c6b44b1c6a46303f7b965e508f1/\n",
            "   creating: stage1_test/1ef68e93964c2d9230100c1347c328f6385a7bc027879dc3d4c055e6fe80cb3c/\n",
            "   creating: stage1_test/259b35151d4a7a5ffdd7ab7f171b142db8cfe40beeee67277fac6adca4d042c4/\n",
            "   creating: stage1_test/295682d9eb5acb5c1976a460c085734bfaf38482b0a3f02591c2bfdcd4128549/\n",
            "   creating: stage1_test/31f1fbe85b8899258ea5bcf5f93f7ac8238660c386aeab40649c715bd2e38a0a/\n",
            "   creating: stage1_test/336d3e4105766f8ad328a7ee9571e743f376f8cbcf6a969ca7e353fe3235c523/\n",
            "   creating: stage1_test/38f5cfb55fc8b048e82a5c895b25fefae7a70c71ab9990c535d1030637bf6a1f/\n",
            "   creating: stage1_test/3c4c675825f7509877bc10497f498c9a2e3433bf922bd870914a2eb21a54fd26/\n",
            "   creating: stage1_test/432f367a4c5b5674de2e2977744d10289a064e5704b21af6607b4975be47c580/\n",
            "   creating: stage1_test/43a71aeb641faa18742cb826772a8566c6c947d7050f9ab15459de6cc2b3b6af/\n",
            "   creating: stage1_test/44afae184c89e6ba55985b4d341acc1ae1e8b6ef96312064e0e6e630e022b078/\n",
            "   creating: stage1_test/4727d94c6a57ed484270fdd8bbc6e3d5f2f15d5476794a4e37a40f2309a091e2/\n",
            "   creating: stage1_test/472b1c5ff988dadc209faea92499bc07f305208dbda29d16262b3d543ac91c71/\n",
            "   creating: stage1_test/4be73d68f433869188fe5e7f09c7f681ed51003da6aa5d19ce368726d8e271ee/\n",
            "   creating: stage1_test/4f949bd8d914bbfa06f40d6a0e2b5b75c38bf53dbcbafc48c97f105bee4f8fac/\n",
            "   creating: stage1_test/505bc0a3928d8aef5ce441c5a611fdd32e1e8eccdc15cc3a52b88030acb50f81/\n",
            "   creating: stage1_test/519dc0d672d1c295fc69b629af8721ccb1a1f136d1976685a68487e62547ffe0/\n",
            "   creating: stage1_test/51c70bb8a299943b27f8b354571272692d8f2705036a1a9562156c76da5f025b/\n",
            "   creating: stage1_test/52b267e20519174e3ce1e1994b5d677804b16bc670aa5f6ffb6344a0fdf63fde/\n",
            "   creating: stage1_test/53df5150ee56253fe5bc91a9230d377bb21f1300f443ba45a758bcb01a15c0e4/\n",
            "   creating: stage1_test/550450e4bff4036fd671decdc5d42fec23578198d6a2fd79179c4368b9d6da18/\n",
            "   creating: stage1_test/5cee644e5ffbef1ba021c7f389b33bafd3b1841f04d3edd7922d5084c2c4e0c7/\n",
            "   creating: stage1_test/648c8ffa496e1716017906d0bf135debfc93386ae86aa3d4adbda9a505985fd9/\n",
            "   creating: stage1_test/697a05c6fe4a07c601d46da80885645ad574ea19b47ee795ccff216c9f1f1808/\n",
            "   creating: stage1_test/699f2992cd71e2e28cf45f81347ff22e76b37541ce88087742884cd0e9aadc68/\n",
            "   creating: stage1_test/78a981bd27ba0c65a9169548665a17bda9f49050d0d3893a6567d1eb92cd003d/\n",
            "   creating: stage1_test/7bdb668e6127b7eafc837a883f0648002bd063c736f55a4f673e787250a3fb04/\n",
            "   creating: stage1_test/7f4cbe0b36b5d09466476a7d4e01f4f976c67872d549f4ff47b3e1e3a2b403af/\n",
            "   creating: stage1_test/8922a6ac8fd0258ec27738ca101867169b20d90a60fc84f93df77acd5bf7c80b/\n",
            "   creating: stage1_test/8b59819fbc92eefe45b1db95c0cc3a467ddcfc755684c7f2ba2f6ccb9ad740ab/\n",
            "   creating: stage1_test/912a679e4b9b1d1a75170254fd675b8c24b664d80ad7ea7e460241a23535a406/\n",
            "   creating: stage1_test/9ab2d381f90b485a68b82bc07f94397a0373e3215ad20935a958738e55f3cfc2/\n",
            "   creating: stage1_test/9f17aea854db13015d19b34cb2022cfdeda44133323fcd6bb3545f7b9404d8ab/\n",
            "   creating: stage1_test/a4816cc1fb76cb3c5e481186833fc0ae9cf426a1406a2607e974e65e9cddba4f/\n",
            "   creating: stage1_test/a984e7fb886aa02e29d112766d3ce26a4f78eac540ce7bbdbd42af2761928f6d/\n",
            "   creating: stage1_test/ab298b962a63e4be9582513aaa84a5e270adba5fd2b16a50e59540524f63c3b8/\n",
            "   creating: stage1_test/ade080c6618cbbb0a25680cf847f312b5e19b22bfe1cafec0436987ebe5b1e7e/\n",
            "   creating: stage1_test/b83d1d77935b6cfd44105b54600ffc4b6bd82de57dec65571bcb117fa8398ba3/\n",
            "   creating: stage1_test/bdc789019cee8ddfae20d5f769299993b4b330b2d38d1218646cf89e77fbbd4d/\n",
            "   creating: stage1_test/c8e79ff4ac55f4b772057de28e539727b7f4f2a3de73bf7a082a0ace86d609eb/\n",
            "   creating: stage1_test/ca20076870e8fb604e61802605a9ac45419c82dd3e23404c56c4869f9502a5ef/\n",
            "   creating: stage1_test/d616d323a9eeb9da1b66f8d5df671d63c092c9919cb2c0b223e29c63257c944d/\n",
            "   creating: stage1_test/d6eb7ce7723e2f6dc13b90b41a29ded27dbd815bad633fdf582447c686018896/\n",
            "   creating: stage1_test/d8d4bf68a76e4e4c5f21de7ac613451f7115a04db686151e78b8ec0b6a22022b/\n",
            "   creating: stage1_test/da6c593410340b19bb212b9f6d274f95b08c0fc8f2570cd66bc5ed42c560acab/\n",
            "   creating: stage1_test/dab46d798d29aff2e99c23f47ed3064f5cafb1644629b015c95a2dd2ee593bb4/\n",
            "   creating: stage1_test/df40099c6306ca1f47fcc8a62e2fa39486d4e223177afdc51b2ad189691802d8/\n",
            "   creating: stage1_test/e17b7aedd251a016c01ef9158e6e4aa940d9f1b35942d86028dc1222192a9258/\n",
            "   creating: stage1_test/eea70a7948d25a9a791dbcb39228af4ea4049fe5ebdee9c04884be8cca3da835/\n",
            "   creating: stage1_test/f0d0ab13ff53adc3c4d57e95a5f83d80b06f2cbc0bf002b52cf7b496612e0ce4/\n",
            "   creating: stage1_test/f5effed21f671bbf4551ecebb7fe95f3be1cf09c16a60afe64d2f0b95be9d1eb/\n",
            "   creating: stage1_test/fac507fa4d1649e8b24c195d990f1fc3ca3633d917839e1751a9d412a14ab5e3/\n",
            "   creating: stage1_test/fe9adb627a6f45747c5a8223b671774791ededf9364f6544be487c540107fa4f/\n",
            "   creating: stage1_test/0114f484a16c152baa2d82fdd43740880a762c93f436c8988ac461c5c9dbe7d5/images/\n",
            "  inflating: stage1_test/0114f484a16c152baa2d82fdd43740880a762c93f436c8988ac461c5c9dbe7d5/images/0114f484a16c152baa2d82fdd43740880a762c93f436c8988ac461c5c9dbe7d5.png  \n",
            "   creating: stage1_test/0999dab07b11bc85fb8464fc36c947fbd8b5d6ec49817361cb780659ca805eac/images/\n",
            "  inflating: stage1_test/0999dab07b11bc85fb8464fc36c947fbd8b5d6ec49817361cb780659ca805eac/images/0999dab07b11bc85fb8464fc36c947fbd8b5d6ec49817361cb780659ca805eac.png  \n",
            "   creating: stage1_test/0a849e0eb15faa8a6d7329c3dd66aabe9a294cccb52ed30a90c8ca99092ae732/images/\n",
            "  inflating: stage1_test/0a849e0eb15faa8a6d7329c3dd66aabe9a294cccb52ed30a90c8ca99092ae732/images/0a849e0eb15faa8a6d7329c3dd66aabe9a294cccb52ed30a90c8ca99092ae732.png  \n",
            "   creating: stage1_test/0e132f71c8b4875c3c2dd7a22997468a3e842b46aa9bd47cf7b0e8b7d63f0925/images/\n",
            "  inflating: stage1_test/0e132f71c8b4875c3c2dd7a22997468a3e842b46aa9bd47cf7b0e8b7d63f0925/images/0e132f71c8b4875c3c2dd7a22997468a3e842b46aa9bd47cf7b0e8b7d63f0925.png  \n",
            "   creating: stage1_test/0ed3555a4bd48046d3b63d8baf03a5aa97e523aa483aaa07459e7afa39fb96c6/images/\n",
            "  inflating: stage1_test/0ed3555a4bd48046d3b63d8baf03a5aa97e523aa483aaa07459e7afa39fb96c6/images/0ed3555a4bd48046d3b63d8baf03a5aa97e523aa483aaa07459e7afa39fb96c6.png  \n",
            "   creating: stage1_test/0f1f896d9ae5a04752d3239c690402c022db4d72c0d2c087d73380896f72c466/images/\n",
            "  inflating: stage1_test/0f1f896d9ae5a04752d3239c690402c022db4d72c0d2c087d73380896f72c466/images/0f1f896d9ae5a04752d3239c690402c022db4d72c0d2c087d73380896f72c466.png  \n",
            "   creating: stage1_test/1747f62148a919c8feb6d607faeebdf504b5e2ad42b6b1710b1189c37ebcdb2c/images/\n",
            "  inflating: stage1_test/1747f62148a919c8feb6d607faeebdf504b5e2ad42b6b1710b1189c37ebcdb2c/images/1747f62148a919c8feb6d607faeebdf504b5e2ad42b6b1710b1189c37ebcdb2c.png  \n",
            "   creating: stage1_test/17b9bf4356db24967c4677b8376ac38f826de73a88b93a8d73a8b452e399cdff/images/\n",
            "  inflating: stage1_test/17b9bf4356db24967c4677b8376ac38f826de73a88b93a8d73a8b452e399cdff/images/17b9bf4356db24967c4677b8376ac38f826de73a88b93a8d73a8b452e399cdff.png  \n",
            "   creating: stage1_test/1879f4f4f05e2bada0ffeb46c128b8df7a79b14c84f38c3e216a69653495153b/images/\n",
            "  inflating: stage1_test/1879f4f4f05e2bada0ffeb46c128b8df7a79b14c84f38c3e216a69653495153b/images/1879f4f4f05e2bada0ffeb46c128b8df7a79b14c84f38c3e216a69653495153b.png  \n",
            "   creating: stage1_test/191b2b2205f2f5cc9da04702c5d422bc249faf8bca1107af792da63cccfba829/images/\n",
            "  inflating: stage1_test/191b2b2205f2f5cc9da04702c5d422bc249faf8bca1107af792da63cccfba829/images/191b2b2205f2f5cc9da04702c5d422bc249faf8bca1107af792da63cccfba829.png  \n",
            "   creating: stage1_test/1962d0c5faf3e85cda80e0578e0cb7aca50826d781620e5c1c4cc586bc69f81a/images/\n",
            "  inflating: stage1_test/1962d0c5faf3e85cda80e0578e0cb7aca50826d781620e5c1c4cc586bc69f81a/images/1962d0c5faf3e85cda80e0578e0cb7aca50826d781620e5c1c4cc586bc69f81a.png  \n",
            "   creating: stage1_test/1cdbfee1951356e7b0a215073828695fe1ead5f8b1add119b6645d2fdc8d844e/images/\n",
            "  inflating: stage1_test/1cdbfee1951356e7b0a215073828695fe1ead5f8b1add119b6645d2fdc8d844e/images/1cdbfee1951356e7b0a215073828695fe1ead5f8b1add119b6645d2fdc8d844e.png  \n",
            "   creating: stage1_test/1d9eacb3161f1e2b45550389ecf7c535c7199c6b44b1c6a46303f7b965e508f1/images/\n",
            "  inflating: stage1_test/1d9eacb3161f1e2b45550389ecf7c535c7199c6b44b1c6a46303f7b965e508f1/images/1d9eacb3161f1e2b45550389ecf7c535c7199c6b44b1c6a46303f7b965e508f1.png  \n",
            "   creating: stage1_test/1ef68e93964c2d9230100c1347c328f6385a7bc027879dc3d4c055e6fe80cb3c/images/\n",
            "  inflating: stage1_test/1ef68e93964c2d9230100c1347c328f6385a7bc027879dc3d4c055e6fe80cb3c/images/1ef68e93964c2d9230100c1347c328f6385a7bc027879dc3d4c055e6fe80cb3c.png  \n",
            "   creating: stage1_test/259b35151d4a7a5ffdd7ab7f171b142db8cfe40beeee67277fac6adca4d042c4/images/\n",
            "  inflating: stage1_test/259b35151d4a7a5ffdd7ab7f171b142db8cfe40beeee67277fac6adca4d042c4/images/259b35151d4a7a5ffdd7ab7f171b142db8cfe40beeee67277fac6adca4d042c4.png  \n",
            "   creating: stage1_test/295682d9eb5acb5c1976a460c085734bfaf38482b0a3f02591c2bfdcd4128549/images/\n",
            "  inflating: stage1_test/295682d9eb5acb5c1976a460c085734bfaf38482b0a3f02591c2bfdcd4128549/images/295682d9eb5acb5c1976a460c085734bfaf38482b0a3f02591c2bfdcd4128549.png  \n",
            "   creating: stage1_test/31f1fbe85b8899258ea5bcf5f93f7ac8238660c386aeab40649c715bd2e38a0a/images/\n",
            "  inflating: stage1_test/31f1fbe85b8899258ea5bcf5f93f7ac8238660c386aeab40649c715bd2e38a0a/images/31f1fbe85b8899258ea5bcf5f93f7ac8238660c386aeab40649c715bd2e38a0a.png  \n",
            "   creating: stage1_test/336d3e4105766f8ad328a7ee9571e743f376f8cbcf6a969ca7e353fe3235c523/images/\n",
            "  inflating: stage1_test/336d3e4105766f8ad328a7ee9571e743f376f8cbcf6a969ca7e353fe3235c523/images/336d3e4105766f8ad328a7ee9571e743f376f8cbcf6a969ca7e353fe3235c523.png  \n",
            "   creating: stage1_test/38f5cfb55fc8b048e82a5c895b25fefae7a70c71ab9990c535d1030637bf6a1f/images/\n",
            "  inflating: stage1_test/38f5cfb55fc8b048e82a5c895b25fefae7a70c71ab9990c535d1030637bf6a1f/images/38f5cfb55fc8b048e82a5c895b25fefae7a70c71ab9990c535d1030637bf6a1f.png  \n",
            "   creating: stage1_test/3c4c675825f7509877bc10497f498c9a2e3433bf922bd870914a2eb21a54fd26/images/\n",
            "  inflating: stage1_test/3c4c675825f7509877bc10497f498c9a2e3433bf922bd870914a2eb21a54fd26/images/3c4c675825f7509877bc10497f498c9a2e3433bf922bd870914a2eb21a54fd26.png  \n",
            "   creating: stage1_test/432f367a4c5b5674de2e2977744d10289a064e5704b21af6607b4975be47c580/images/\n",
            "  inflating: stage1_test/432f367a4c5b5674de2e2977744d10289a064e5704b21af6607b4975be47c580/images/432f367a4c5b5674de2e2977744d10289a064e5704b21af6607b4975be47c580.png  \n",
            "   creating: stage1_test/43a71aeb641faa18742cb826772a8566c6c947d7050f9ab15459de6cc2b3b6af/images/\n",
            "  inflating: stage1_test/43a71aeb641faa18742cb826772a8566c6c947d7050f9ab15459de6cc2b3b6af/images/43a71aeb641faa18742cb826772a8566c6c947d7050f9ab15459de6cc2b3b6af.png  \n",
            "   creating: stage1_test/44afae184c89e6ba55985b4d341acc1ae1e8b6ef96312064e0e6e630e022b078/images/\n",
            "  inflating: stage1_test/44afae184c89e6ba55985b4d341acc1ae1e8b6ef96312064e0e6e630e022b078/images/44afae184c89e6ba55985b4d341acc1ae1e8b6ef96312064e0e6e630e022b078.png  \n",
            "   creating: stage1_test/4727d94c6a57ed484270fdd8bbc6e3d5f2f15d5476794a4e37a40f2309a091e2/images/\n",
            "  inflating: stage1_test/4727d94c6a57ed484270fdd8bbc6e3d5f2f15d5476794a4e37a40f2309a091e2/images/4727d94c6a57ed484270fdd8bbc6e3d5f2f15d5476794a4e37a40f2309a091e2.png  \n",
            "   creating: stage1_test/472b1c5ff988dadc209faea92499bc07f305208dbda29d16262b3d543ac91c71/images/\n",
            "  inflating: stage1_test/472b1c5ff988dadc209faea92499bc07f305208dbda29d16262b3d543ac91c71/images/472b1c5ff988dadc209faea92499bc07f305208dbda29d16262b3d543ac91c71.png  \n",
            "   creating: stage1_test/4be73d68f433869188fe5e7f09c7f681ed51003da6aa5d19ce368726d8e271ee/images/\n",
            "  inflating: stage1_test/4be73d68f433869188fe5e7f09c7f681ed51003da6aa5d19ce368726d8e271ee/images/4be73d68f433869188fe5e7f09c7f681ed51003da6aa5d19ce368726d8e271ee.png  \n",
            "   creating: stage1_test/4f949bd8d914bbfa06f40d6a0e2b5b75c38bf53dbcbafc48c97f105bee4f8fac/images/\n",
            "  inflating: stage1_test/4f949bd8d914bbfa06f40d6a0e2b5b75c38bf53dbcbafc48c97f105bee4f8fac/images/4f949bd8d914bbfa06f40d6a0e2b5b75c38bf53dbcbafc48c97f105bee4f8fac.png  \n",
            "   creating: stage1_test/505bc0a3928d8aef5ce441c5a611fdd32e1e8eccdc15cc3a52b88030acb50f81/images/\n",
            "  inflating: stage1_test/505bc0a3928d8aef5ce441c5a611fdd32e1e8eccdc15cc3a52b88030acb50f81/images/505bc0a3928d8aef5ce441c5a611fdd32e1e8eccdc15cc3a52b88030acb50f81.png  \n",
            "   creating: stage1_test/519dc0d672d1c295fc69b629af8721ccb1a1f136d1976685a68487e62547ffe0/images/\n",
            "  inflating: stage1_test/519dc0d672d1c295fc69b629af8721ccb1a1f136d1976685a68487e62547ffe0/images/519dc0d672d1c295fc69b629af8721ccb1a1f136d1976685a68487e62547ffe0.png  \n",
            "   creating: stage1_test/51c70bb8a299943b27f8b354571272692d8f2705036a1a9562156c76da5f025b/images/\n",
            "  inflating: stage1_test/51c70bb8a299943b27f8b354571272692d8f2705036a1a9562156c76da5f025b/images/51c70bb8a299943b27f8b354571272692d8f2705036a1a9562156c76da5f025b.png  \n",
            "   creating: stage1_test/52b267e20519174e3ce1e1994b5d677804b16bc670aa5f6ffb6344a0fdf63fde/images/\n",
            "  inflating: stage1_test/52b267e20519174e3ce1e1994b5d677804b16bc670aa5f6ffb6344a0fdf63fde/images/52b267e20519174e3ce1e1994b5d677804b16bc670aa5f6ffb6344a0fdf63fde.png  \n",
            "   creating: stage1_test/53df5150ee56253fe5bc91a9230d377bb21f1300f443ba45a758bcb01a15c0e4/images/\n",
            "  inflating: stage1_test/53df5150ee56253fe5bc91a9230d377bb21f1300f443ba45a758bcb01a15c0e4/images/53df5150ee56253fe5bc91a9230d377bb21f1300f443ba45a758bcb01a15c0e4.png  \n",
            "   creating: stage1_test/550450e4bff4036fd671decdc5d42fec23578198d6a2fd79179c4368b9d6da18/images/\n",
            "  inflating: stage1_test/550450e4bff4036fd671decdc5d42fec23578198d6a2fd79179c4368b9d6da18/images/550450e4bff4036fd671decdc5d42fec23578198d6a2fd79179c4368b9d6da18.png  \n",
            "   creating: stage1_test/5cee644e5ffbef1ba021c7f389b33bafd3b1841f04d3edd7922d5084c2c4e0c7/images/\n",
            "  inflating: stage1_test/5cee644e5ffbef1ba021c7f389b33bafd3b1841f04d3edd7922d5084c2c4e0c7/images/5cee644e5ffbef1ba021c7f389b33bafd3b1841f04d3edd7922d5084c2c4e0c7.png  \n",
            "   creating: stage1_test/648c8ffa496e1716017906d0bf135debfc93386ae86aa3d4adbda9a505985fd9/images/\n",
            "  inflating: stage1_test/648c8ffa496e1716017906d0bf135debfc93386ae86aa3d4adbda9a505985fd9/images/648c8ffa496e1716017906d0bf135debfc93386ae86aa3d4adbda9a505985fd9.png  \n",
            "   creating: stage1_test/697a05c6fe4a07c601d46da80885645ad574ea19b47ee795ccff216c9f1f1808/images/\n",
            "  inflating: stage1_test/697a05c6fe4a07c601d46da80885645ad574ea19b47ee795ccff216c9f1f1808/images/697a05c6fe4a07c601d46da80885645ad574ea19b47ee795ccff216c9f1f1808.png  \n",
            "   creating: stage1_test/699f2992cd71e2e28cf45f81347ff22e76b37541ce88087742884cd0e9aadc68/images/\n",
            "  inflating: stage1_test/699f2992cd71e2e28cf45f81347ff22e76b37541ce88087742884cd0e9aadc68/images/699f2992cd71e2e28cf45f81347ff22e76b37541ce88087742884cd0e9aadc68.png  \n",
            "   creating: stage1_test/78a981bd27ba0c65a9169548665a17bda9f49050d0d3893a6567d1eb92cd003d/images/\n",
            "  inflating: stage1_test/78a981bd27ba0c65a9169548665a17bda9f49050d0d3893a6567d1eb92cd003d/images/78a981bd27ba0c65a9169548665a17bda9f49050d0d3893a6567d1eb92cd003d.png  \n",
            "   creating: stage1_test/7bdb668e6127b7eafc837a883f0648002bd063c736f55a4f673e787250a3fb04/images/\n",
            "  inflating: stage1_test/7bdb668e6127b7eafc837a883f0648002bd063c736f55a4f673e787250a3fb04/images/7bdb668e6127b7eafc837a883f0648002bd063c736f55a4f673e787250a3fb04.png  \n",
            "   creating: stage1_test/7f4cbe0b36b5d09466476a7d4e01f4f976c67872d549f4ff47b3e1e3a2b403af/images/\n",
            "  inflating: stage1_test/7f4cbe0b36b5d09466476a7d4e01f4f976c67872d549f4ff47b3e1e3a2b403af/images/7f4cbe0b36b5d09466476a7d4e01f4f976c67872d549f4ff47b3e1e3a2b403af.png  \n",
            "   creating: stage1_test/8922a6ac8fd0258ec27738ca101867169b20d90a60fc84f93df77acd5bf7c80b/images/\n",
            "  inflating: stage1_test/8922a6ac8fd0258ec27738ca101867169b20d90a60fc84f93df77acd5bf7c80b/images/8922a6ac8fd0258ec27738ca101867169b20d90a60fc84f93df77acd5bf7c80b.png  \n",
            "   creating: stage1_test/8b59819fbc92eefe45b1db95c0cc3a467ddcfc755684c7f2ba2f6ccb9ad740ab/images/\n",
            "  inflating: stage1_test/8b59819fbc92eefe45b1db95c0cc3a467ddcfc755684c7f2ba2f6ccb9ad740ab/images/8b59819fbc92eefe45b1db95c0cc3a467ddcfc755684c7f2ba2f6ccb9ad740ab.png  \n",
            "   creating: stage1_test/912a679e4b9b1d1a75170254fd675b8c24b664d80ad7ea7e460241a23535a406/images/\n",
            "  inflating: stage1_test/912a679e4b9b1d1a75170254fd675b8c24b664d80ad7ea7e460241a23535a406/images/912a679e4b9b1d1a75170254fd675b8c24b664d80ad7ea7e460241a23535a406.png  \n",
            "   creating: stage1_test/9ab2d381f90b485a68b82bc07f94397a0373e3215ad20935a958738e55f3cfc2/images/\n",
            "  inflating: stage1_test/9ab2d381f90b485a68b82bc07f94397a0373e3215ad20935a958738e55f3cfc2/images/9ab2d381f90b485a68b82bc07f94397a0373e3215ad20935a958738e55f3cfc2.png  \n",
            "   creating: stage1_test/9f17aea854db13015d19b34cb2022cfdeda44133323fcd6bb3545f7b9404d8ab/images/\n",
            "  inflating: stage1_test/9f17aea854db13015d19b34cb2022cfdeda44133323fcd6bb3545f7b9404d8ab/images/9f17aea854db13015d19b34cb2022cfdeda44133323fcd6bb3545f7b9404d8ab.png  \n",
            "   creating: stage1_test/a4816cc1fb76cb3c5e481186833fc0ae9cf426a1406a2607e974e65e9cddba4f/images/\n",
            "  inflating: stage1_test/a4816cc1fb76cb3c5e481186833fc0ae9cf426a1406a2607e974e65e9cddba4f/images/a4816cc1fb76cb3c5e481186833fc0ae9cf426a1406a2607e974e65e9cddba4f.png  \n",
            "   creating: stage1_test/a984e7fb886aa02e29d112766d3ce26a4f78eac540ce7bbdbd42af2761928f6d/images/\n",
            "  inflating: stage1_test/a984e7fb886aa02e29d112766d3ce26a4f78eac540ce7bbdbd42af2761928f6d/images/a984e7fb886aa02e29d112766d3ce26a4f78eac540ce7bbdbd42af2761928f6d.png  \n",
            "   creating: stage1_test/ab298b962a63e4be9582513aaa84a5e270adba5fd2b16a50e59540524f63c3b8/images/\n",
            "  inflating: stage1_test/ab298b962a63e4be9582513aaa84a5e270adba5fd2b16a50e59540524f63c3b8/images/ab298b962a63e4be9582513aaa84a5e270adba5fd2b16a50e59540524f63c3b8.png  \n",
            "   creating: stage1_test/ade080c6618cbbb0a25680cf847f312b5e19b22bfe1cafec0436987ebe5b1e7e/images/\n",
            "  inflating: stage1_test/ade080c6618cbbb0a25680cf847f312b5e19b22bfe1cafec0436987ebe5b1e7e/images/ade080c6618cbbb0a25680cf847f312b5e19b22bfe1cafec0436987ebe5b1e7e.png  \n",
            "   creating: stage1_test/b83d1d77935b6cfd44105b54600ffc4b6bd82de57dec65571bcb117fa8398ba3/images/\n",
            "  inflating: stage1_test/b83d1d77935b6cfd44105b54600ffc4b6bd82de57dec65571bcb117fa8398ba3/images/b83d1d77935b6cfd44105b54600ffc4b6bd82de57dec65571bcb117fa8398ba3.png  \n",
            "   creating: stage1_test/bdc789019cee8ddfae20d5f769299993b4b330b2d38d1218646cf89e77fbbd4d/images/\n",
            "  inflating: stage1_test/bdc789019cee8ddfae20d5f769299993b4b330b2d38d1218646cf89e77fbbd4d/images/bdc789019cee8ddfae20d5f769299993b4b330b2d38d1218646cf89e77fbbd4d.png  \n",
            "   creating: stage1_test/c8e79ff4ac55f4b772057de28e539727b7f4f2a3de73bf7a082a0ace86d609eb/images/\n",
            "  inflating: stage1_test/c8e79ff4ac55f4b772057de28e539727b7f4f2a3de73bf7a082a0ace86d609eb/images/c8e79ff4ac55f4b772057de28e539727b7f4f2a3de73bf7a082a0ace86d609eb.png  \n",
            "   creating: stage1_test/ca20076870e8fb604e61802605a9ac45419c82dd3e23404c56c4869f9502a5ef/images/\n",
            "  inflating: stage1_test/ca20076870e8fb604e61802605a9ac45419c82dd3e23404c56c4869f9502a5ef/images/ca20076870e8fb604e61802605a9ac45419c82dd3e23404c56c4869f9502a5ef.png  \n",
            "   creating: stage1_test/d616d323a9eeb9da1b66f8d5df671d63c092c9919cb2c0b223e29c63257c944d/images/\n",
            "  inflating: stage1_test/d616d323a9eeb9da1b66f8d5df671d63c092c9919cb2c0b223e29c63257c944d/images/d616d323a9eeb9da1b66f8d5df671d63c092c9919cb2c0b223e29c63257c944d.png  \n",
            "   creating: stage1_test/d6eb7ce7723e2f6dc13b90b41a29ded27dbd815bad633fdf582447c686018896/images/\n",
            "  inflating: stage1_test/d6eb7ce7723e2f6dc13b90b41a29ded27dbd815bad633fdf582447c686018896/images/d6eb7ce7723e2f6dc13b90b41a29ded27dbd815bad633fdf582447c686018896.png  \n",
            "   creating: stage1_test/d8d4bf68a76e4e4c5f21de7ac613451f7115a04db686151e78b8ec0b6a22022b/images/\n",
            "  inflating: stage1_test/d8d4bf68a76e4e4c5f21de7ac613451f7115a04db686151e78b8ec0b6a22022b/images/d8d4bf68a76e4e4c5f21de7ac613451f7115a04db686151e78b8ec0b6a22022b.png  \n",
            "   creating: stage1_test/da6c593410340b19bb212b9f6d274f95b08c0fc8f2570cd66bc5ed42c560acab/images/\n",
            "  inflating: stage1_test/da6c593410340b19bb212b9f6d274f95b08c0fc8f2570cd66bc5ed42c560acab/images/da6c593410340b19bb212b9f6d274f95b08c0fc8f2570cd66bc5ed42c560acab.png  \n",
            "   creating: stage1_test/dab46d798d29aff2e99c23f47ed3064f5cafb1644629b015c95a2dd2ee593bb4/images/\n",
            "  inflating: stage1_test/dab46d798d29aff2e99c23f47ed3064f5cafb1644629b015c95a2dd2ee593bb4/images/dab46d798d29aff2e99c23f47ed3064f5cafb1644629b015c95a2dd2ee593bb4.png  \n",
            "   creating: stage1_test/df40099c6306ca1f47fcc8a62e2fa39486d4e223177afdc51b2ad189691802d8/images/\n",
            "  inflating: stage1_test/df40099c6306ca1f47fcc8a62e2fa39486d4e223177afdc51b2ad189691802d8/images/df40099c6306ca1f47fcc8a62e2fa39486d4e223177afdc51b2ad189691802d8.png  \n",
            "   creating: stage1_test/e17b7aedd251a016c01ef9158e6e4aa940d9f1b35942d86028dc1222192a9258/images/\n",
            "  inflating: stage1_test/e17b7aedd251a016c01ef9158e6e4aa940d9f1b35942d86028dc1222192a9258/images/e17b7aedd251a016c01ef9158e6e4aa940d9f1b35942d86028dc1222192a9258.png  \n",
            "   creating: stage1_test/eea70a7948d25a9a791dbcb39228af4ea4049fe5ebdee9c04884be8cca3da835/images/\n",
            "  inflating: stage1_test/eea70a7948d25a9a791dbcb39228af4ea4049fe5ebdee9c04884be8cca3da835/images/eea70a7948d25a9a791dbcb39228af4ea4049fe5ebdee9c04884be8cca3da835.png  \n",
            "   creating: stage1_test/f0d0ab13ff53adc3c4d57e95a5f83d80b06f2cbc0bf002b52cf7b496612e0ce4/images/\n",
            "  inflating: stage1_test/f0d0ab13ff53adc3c4d57e95a5f83d80b06f2cbc0bf002b52cf7b496612e0ce4/images/f0d0ab13ff53adc3c4d57e95a5f83d80b06f2cbc0bf002b52cf7b496612e0ce4.png  \n",
            "   creating: stage1_test/f5effed21f671bbf4551ecebb7fe95f3be1cf09c16a60afe64d2f0b95be9d1eb/images/\n",
            "  inflating: stage1_test/f5effed21f671bbf4551ecebb7fe95f3be1cf09c16a60afe64d2f0b95be9d1eb/images/f5effed21f671bbf4551ecebb7fe95f3be1cf09c16a60afe64d2f0b95be9d1eb.png  \n",
            "   creating: stage1_test/fac507fa4d1649e8b24c195d990f1fc3ca3633d917839e1751a9d412a14ab5e3/images/\n",
            "  inflating: stage1_test/fac507fa4d1649e8b24c195d990f1fc3ca3633d917839e1751a9d412a14ab5e3/images/fac507fa4d1649e8b24c195d990f1fc3ca3633d917839e1751a9d412a14ab5e3.png  \n",
            "   creating: stage1_test/fe9adb627a6f45747c5a8223b671774791ededf9364f6544be487c540107fa4f/images/\n",
            "  inflating: stage1_test/fe9adb627a6f45747c5a8223b671774791ededf9364f6544be487c540107fa4f/images/fe9adb627a6f45747c5a8223b671774791ededf9364f6544be487c540107fa4f.png  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/Downloads/stage1_train_labels.csv.zip\n",
            "  inflating: ./stage1_train_labels.csv  \n",
            "--2018-04-10 04:00:54--  https://github.com/matterport/Mask_RCNN/releases/download/v2.0/mask_rcnn_coco.h5\n",
            "Resolving github.com (github.com)... 192.30.253.113, 192.30.253.112\n",
            "Connecting to github.com (github.com)|192.30.253.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-production-release-asset-2e65be.s3.amazonaws.com/107595270/872d3234-d21f-11e7-9a51-7b4bc8075835?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20180410%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20180410T040054Z&X-Amz-Expires=300&X-Amz-Signature=ca349f7a0077f578c42e5006dc8f11ba6023e5091c1bdc4dbe79bc7ea2abd906&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Dmask_rcnn_coco.h5&response-content-type=application%2Foctet-stream [following]\n",
            "--2018-04-10 04:00:54--  https://github-production-release-asset-2e65be.s3.amazonaws.com/107595270/872d3234-d21f-11e7-9a51-7b4bc8075835?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20180410%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20180410T040054Z&X-Amz-Expires=300&X-Amz-Signature=ca349f7a0077f578c42e5006dc8f11ba6023e5091c1bdc4dbe79bc7ea2abd906&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Dmask_rcnn_coco.h5&response-content-type=application%2Foctet-stream\n",
            "Resolving github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)... 52.216.160.131\n",
            "Connecting to github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|52.216.160.131|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 257557808 (246M) [application/octet-stream]\n",
            "Saving to: mask_rcnn_coco.h5\n",
            "\n",
            "mask_rcnn_coco.h5   100%[===================>] 245.63M  50.7MB/s    in 4.9s    \n",
            "\n",
            "2018-04-10 04:00:59 (50.1 MB/s) - mask_rcnn_coco.h5 saved [257557808/257557808]\n",
            "\n",
            "Cloning into 'kaggle-ds-bowl-2018-baseline'...\n",
            "remote: Counting objects: 125, done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 125 (delta 0), reused 2 (delta 0), pack-reused 122\u001b[K\n",
            "Receiving objects: 100% (125/125), 10.94 MiB | 36.86 MiB/s, done.\n",
            "Resolving deltas: 100% (66/66), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8aKj1wKLhOPt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 3 of 6: Train and Inference procs\n",
        "Implement 'train.py' and 'inference.py' as procedures so we can run them from within the notebook and pass some parameters"
      ]
    },
    {
      "metadata": {
        "id": "buIvNXkncSB9",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 823
        },
        "outputId": "a8d1b2e9-2d9c-4d81-92bb-5bfa40f66b9b",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523333013349,
          "user_tz": 300,
          "elapsed": 11147,
          "user": {
            "displayName": "Aftab Khan",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "115745872669652090393"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install -q tqdm\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import random\n",
        "import math\n",
        "import time\n",
        "import model as modellib\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "from bowl_config import bowl_config\n",
        "from bowl_dataset import BowlDataset\n",
        "import utils\n",
        "import model as modellib\n",
        "from model import log\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "from inference_config import inference_config\n",
        "from bowl_dataset import BowlDataset\n",
        "from utils import rle_encode, rle_decode, rle_to_string\n",
        "import functions as f\n",
        "\n",
        "#######################################################################################\n",
        "# Module train.py copied here and made into a procedure with two parameters, \n",
        "# 'init' and 'ep'. See values of 'init' below. 'ep' is for how many epochs to train with.\n",
        "########################################################################################\n",
        "def train(init,ep):\n",
        "\n",
        "  # Root directory of the project\n",
        "  ROOT_DIR = os.getcwd()\n",
        "\n",
        "  # Directory to save logs and trained model\n",
        "  MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
        "\n",
        "  # Local path to trained weights file\n",
        "  COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
        "  # Download COCO trained weights from Releases if needed\n",
        "  if not os.path.exists(COCO_MODEL_PATH):\n",
        "      utils.download_trained_weights(COCO_MODEL_PATH)\n",
        "\n",
        "  model = modellib.MaskRCNN(mode=\"training\", config=bowl_config,\n",
        "                            model_dir=MODEL_DIR)\n",
        "\n",
        "  # Which weights to start with?\n",
        "  init_with = init  # imagenet, coco, or last\n",
        "\n",
        "  if init_with == \"imagenet\":\n",
        "      model.load_weights(model.get_imagenet_weights(), by_name=True)\n",
        "  elif init_with == \"coco\":\n",
        "      # Load weights trained on MS COCO, but skip layers that\n",
        "      # are different due to the different number of classes\n",
        "      # See README for instructions to download the COCO weights\n",
        "      model.load_weights(COCO_MODEL_PATH, by_name=True,\n",
        "                         exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
        "                                  \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
        "  elif init_with == \"last\":\n",
        "      # Load the last model you trained and continue training\n",
        "      model.load_weights(model.find_last()[1], by_name=True)\n",
        "\n",
        "  # Training dataset\n",
        "  dataset_train = BowlDataset()\n",
        "  dataset_train.load_bowl('stage1_train')\n",
        "  dataset_train.prepare()\n",
        "\n",
        "  # # Validation dataset\n",
        "  dataset_val = BowlDataset()\n",
        "  dataset_val.load_bowl('stage1_train')\n",
        "  dataset_val.prepare()\n",
        "\n",
        "  # Train the head branches\n",
        "  # Passing layers=\"heads\" freezes all layers except the head\n",
        "  # layers. You can also pass a regular expression to select\n",
        "  # which layers to train by name pattern.\n",
        "  #model.train(dataset_train, dataset_val, \n",
        "  #            learning_rate=bowl_config.LEARNING_RATE, \n",
        "  #            epochs=1, \n",
        "  #            layers='heads')\n",
        "  model.keras_model.summary()\n",
        "  model.train(dataset_train, dataset_val, \n",
        "              learning_rate=bowl_config.LEARNING_RATE / 10,\n",
        "              epochs=ep, \n",
        "              layers=\"all\")\n",
        "    \n",
        "#######################################################################################\n",
        "# Module inference.py copied here and made into a procedure with 'fn' parameter. 'fn' is \n",
        "# the filename of the csv file to write the predictions for submission.\n",
        "########################################################################################y\n",
        "def infer(fn):\n",
        "\n",
        "  ROOT_DIR = os.getcwd()\n",
        "  MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
        "\n",
        "  # Recreate the model in inference mode\n",
        "  model = modellib.MaskRCNN(mode=\"inference\", \n",
        "                            config=inference_config,\n",
        "                            model_dir=MODEL_DIR)\n",
        "\n",
        "  # Get path to saved weights\n",
        "  # Either set a specific path or find last trained weights\n",
        "  # model_path = os.path.join(ROOT_DIR, \".h5 file name here\")\n",
        "  model_path = model.find_last()[1]\n",
        "\n",
        "  # Load trained weights (fill in path to trained weights here)\n",
        "  assert model_path != \"\", \"Provide path to trained weights\"\n",
        "  print(\"Loading weights from \", model_path)\n",
        "  model.load_weights(model_path, by_name=True)\n",
        "\n",
        "  dataset_test = BowlDataset()\n",
        "  dataset_test.load_bowl('stage1_test')\n",
        "  dataset_test.prepare()\n",
        "\n",
        "  output = []\n",
        "  sample_submission = pd.read_csv('stage1_sample_submission.csv')\n",
        "  ImageId = []\n",
        "  EncodedPixels = []\n",
        "  for image_id in tqdm(sample_submission.ImageId):\n",
        "      image_path = os.path.join('stage1_test', image_id, 'images', image_id + '.png')\n",
        "\n",
        "      original_image = cv2.imread(image_path)\n",
        "      results = model.detect([original_image], verbose=0)\n",
        "      r = results[0]\n",
        "\n",
        "      masks = r['masks']\n",
        "      ImageId_batch, EncodedPixels_batch = f.numpy2encoding_no_overlap2(masks, image_id, r['scores'])\n",
        "      ImageId += ImageId_batch\n",
        "      EncodedPixels += EncodedPixels_batch\n",
        "\n",
        "  f.write2csv(fn, ImageId, EncodedPixels)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Configurations:\n",
            "BACKBONE_SHAPES                [[128 128]\n",
            " [ 64  64]\n",
            " [ 32  32]\n",
            " [ 16  16]\n",
            " [  8   8]]\n",
            "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
            "BATCH_SIZE                     2\n",
            "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
            "DETECTION_MAX_INSTANCES        512\n",
            "DETECTION_MIN_CONFIDENCE       0.7\n",
            "DETECTION_NMS_THRESHOLD        0.3\n",
            "GPU_COUNT                      1\n",
            "IMAGES_PER_GPU                 2\n",
            "IMAGE_MAX_DIM                  512\n",
            "IMAGE_MIN_DIM                  512\n",
            "IMAGE_PADDING                  True\n",
            "IMAGE_SHAPE                    [512 512   3]\n",
            "LEARNING_MOMENTUM              0.9\n",
            "LEARNING_RATE                  0.001\n",
            "MASK_POOL_SIZE                 14\n",
            "MASK_SHAPE                     [28, 28]\n",
            "MAX_GT_INSTANCES               256\n",
            "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
            "MINI_MASK_SHAPE                (56, 56)\n",
            "NAME                           bowl\n",
            "NUM_CLASSES                    2\n",
            "POOL_SIZE                      7\n",
            "POST_NMS_ROIS_INFERENCE        1000\n",
            "POST_NMS_ROIS_TRAINING         2000\n",
            "RESNET_ARCHITECTURE            resnet50\n",
            "ROI_POSITIVE_RATIO             0.33\n",
            "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
            "RPN_ANCHOR_SCALES              (8, 16, 32, 64, 128)\n",
            "RPN_ANCHOR_STRIDE              1\n",
            "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
            "RPN_NMS_THRESHOLD              0.7\n",
            "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
            "STEPS_PER_EPOCH                None\n",
            "TRAIN_ROIS_PER_IMAGE           600\n",
            "USE_MINI_MASK                  True\n",
            "USE_RPN_ROIS                   True\n",
            "VALIDATION_STEPS               5\n",
            "WEIGHT_DECAY                   0.0001\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-ValcMCKhOPx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 4 of 6:Procedures to save and retrive weight files to Google Drive.\n",
        "\n",
        "##### Note: When the following cell is run (specifically 'auth.authenticate_user()') first time for a Google Colab session, it will open a blank box below the cell along with a web link (URL). Click on the URL to allow permission and get a long authentication key. Copy the authentication key and paste it into the blank box and press enter. Only required once for a session."
      ]
    },
    {
      "metadata": {
        "id": "zOU-Hm-MmcKg",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.files import GoogleDriveFile\n",
        "from pydrive.auth import GoogleAuth\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import glob\n",
        "\n",
        "auth.authenticate_user()\n",
        "\n",
        "# Function to save/load file 'fn' to Google Drive.\n",
        "def ToGDrive(fn):  \n",
        "  # 1. Authenticate and create the PyDrive client.\n",
        "  auth.authenticate_user()\n",
        "  gauth = GoogleAuth()\n",
        "  gauth.credentials = GoogleCredentials.get_application_default()\n",
        "  gdfile=GoogleDriveFile(gauth)\n",
        "\n",
        "  #load file TO Google Drive\n",
        "  gdfile.SetContentFile(fn)\n",
        "  gdfile.Upload()\n",
        "  if gdfile.uploaded == True:\n",
        "    f\"File {gdfile['title']} uploaded. File ID:{gdfile['id']}\"\n",
        "  return gdfile\n",
        "\n",
        "# Function to save/load the trained weights file generated by the RCNN to Google Drive\n",
        "def dl_wts():\n",
        "  \n",
        "  directory = 'logs/'\n",
        "  dn=max([os.path.join(directory,d) for d in os.listdir(directory)], key=os.path.getmtime)\n",
        "  dn=os.path.join(dn,'mask_rcnn_bowl_*')\n",
        "  list_of_files=glob.glob(dn)\n",
        "  latest_file = max(list_of_files, key=os.path.getctime)\n",
        "  print(latest_file)\n",
        "  ToGDrive(latest_file)\n",
        "\n",
        "# Function to save file 'fn' to your computer\n",
        "def local_download(fn):\n",
        "  from google.colab import files\n",
        "  files.download(fn)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Itayim_Sl9tj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 5 of 6: Run the model and make predictions\n",
        "\n",
        "Train the RCNN using the 'coco' model with upto 20 epochs in a loop:\n",
        "- Train the model for 5 epoch with init = 'coco'\n",
        "- Save the weights file on Google Drive after 5 epochs\n",
        "- Train the model for the next 5 epochs\n",
        "- Again the save the weights and so on"
      ]
    },
    {
      "metadata": {
        "id": "NeHoHgshSgY0",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 12311
        },
        "outputId": "735c3768-ed0d-47aa-b64d-ecdf87c5150e",
        "executionInfo": {
          "elapsed": 3521529,
          "status": "error",
          "timestamp": 1522815946342,
          "user": {
            "displayName": "Aftab Khan",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "115745872669652090393"
          },
          "user_tz": 300
        }
      },
      "cell_type": "code",
      "source": [
        "init='coco'  # a parameter for the 'train' procedure to load the model type:'imagenet', 'coco', or 'last,\n",
        "             # where 'last' means to use the last run model.\n",
        "total_ep=25  # total number of epochs to run  \n",
        "step=5       # after every 'step' number of epochs, save the weights to Google Drive\n",
        "start=5      # start with training up to 5 epochs \n",
        "\n",
        "fn='submission.csv'  # name of the submission file to be produced\n",
        "for x in range(start,total_ep,step):\n",
        "  train(init,x)               # Train the model for 'step' number of epochs\n",
        "  init='last'                 # Set this to 'last' so training will start from last epoch\n",
        "  #fn='submepoch'+str(x)+'.csv'\n",
        "  dl_wts()                    # Save the training weights file to Google Drive\n",
        "  infer(fn)                   # make predictions and store in csv file for submission\n",
        "  #local_download(fn)         # uncomment this if you want the csv file to be downloaded to your computer as well"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading weights from  /content/logs/bowl20180403T0311/mask_rcnn_bowl_0030.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/65 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/scipy/misc/pilutil.py:482: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if issubdtype(ts, int):\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/misc/pilutil.py:485: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
            "  elif issubdtype(type(size), float):\n",
            "100%|| 65/65 [00:32<00:00,  2.02it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_image (InputLayer)        (None, 512, 512, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_4 (ZeroPadding2D (None, 518, 518, 3)  0           input_image[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 256, 256, 64) 9472        zero_padding2d_4[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNorm)            (None, 256, 256, 64) 256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_121 (Activation)     (None, 256, 256, 64) 0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 128, 128, 64) 0           activation_121[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 128, 128, 64) 4160        max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNorm)       (None, 128, 128, 64) 256         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_122 (Activation)     (None, 128, 128, 64) 0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 128, 128, 64) 36928       activation_122[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNorm)       (None, 128, 128, 64) 256         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_123 (Activation)     (None, 128, 128, 64) 0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 128, 128, 256 16640       activation_123[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 128, 128, 256 16640       max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNorm)       (None, 128, 128, 256 1024        res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNorm)        (None, 128, 128, 256 1024        res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_49 (Add)                    (None, 128, 128, 256 0           bn2a_branch2c[0][0]              \n",
            "                                                                 bn2a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res2a_out (Activation)          (None, 128, 128, 256 0           add_49[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 128, 128, 64) 16448       res2a_out[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNorm)       (None, 128, 128, 64) 256         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_124 (Activation)     (None, 128, 128, 64) 0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 128, 128, 64) 36928       activation_124[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNorm)       (None, 128, 128, 64) 256         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_125 (Activation)     (None, 128, 128, 64) 0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 128, 128, 256 16640       activation_125[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNorm)       (None, 128, 128, 256 1024        res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_50 (Add)                    (None, 128, 128, 256 0           bn2b_branch2c[0][0]              \n",
            "                                                                 res2a_out[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "res2b_out (Activation)          (None, 128, 128, 256 0           add_50[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 128, 128, 64) 16448       res2b_out[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNorm)       (None, 128, 128, 64) 256         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_126 (Activation)     (None, 128, 128, 64) 0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 128, 128, 64) 36928       activation_126[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNorm)       (None, 128, 128, 64) 256         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_127 (Activation)     (None, 128, 128, 64) 0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 128, 128, 256 16640       activation_127[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNorm)       (None, 128, 128, 256 1024        res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_51 (Add)                    (None, 128, 128, 256 0           bn2c_branch2c[0][0]              \n",
            "                                                                 res2b_out[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "res2c_out (Activation)          (None, 128, 128, 256 0           add_51[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 64, 64, 128)  32896       res2c_out[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNorm)       (None, 64, 64, 128)  512         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_128 (Activation)     (None, 64, 64, 128)  0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 64, 64, 128)  147584      activation_128[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNorm)       (None, 64, 64, 128)  512         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_129 (Activation)     (None, 64, 64, 128)  0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 64, 64, 512)  66048       activation_129[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 64, 64, 512)  131584      res2c_out[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNorm)       (None, 64, 64, 512)  2048        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNorm)        (None, 64, 64, 512)  2048        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_52 (Add)                    (None, 64, 64, 512)  0           bn3a_branch2c[0][0]              \n",
            "                                                                 bn3a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res3a_out (Activation)          (None, 64, 64, 512)  0           add_52[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 64, 64, 128)  65664       res3a_out[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNorm)       (None, 64, 64, 128)  512         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_130 (Activation)     (None, 64, 64, 128)  0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 64, 64, 128)  147584      activation_130[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNorm)       (None, 64, 64, 128)  512         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_131 (Activation)     (None, 64, 64, 128)  0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 64, 64, 512)  66048       activation_131[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNorm)       (None, 64, 64, 512)  2048        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_53 (Add)                    (None, 64, 64, 512)  0           bn3b_branch2c[0][0]              \n",
            "                                                                 res3a_out[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "res3b_out (Activation)          (None, 64, 64, 512)  0           add_53[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 64, 64, 128)  65664       res3b_out[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNorm)       (None, 64, 64, 128)  512         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_132 (Activation)     (None, 64, 64, 128)  0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 64, 64, 128)  147584      activation_132[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNorm)       (None, 64, 64, 128)  512         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_133 (Activation)     (None, 64, 64, 128)  0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 64, 64, 512)  66048       activation_133[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNorm)       (None, 64, 64, 512)  2048        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_54 (Add)                    (None, 64, 64, 512)  0           bn3c_branch2c[0][0]              \n",
            "                                                                 res3b_out[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "res3c_out (Activation)          (None, 64, 64, 512)  0           add_54[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 64, 64, 128)  65664       res3c_out[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNorm)       (None, 64, 64, 128)  512         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_134 (Activation)     (None, 64, 64, 128)  0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 64, 64, 128)  147584      activation_134[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNorm)       (None, 64, 64, 128)  512         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_135 (Activation)     (None, 64, 64, 128)  0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 64, 64, 512)  66048       activation_135[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNorm)       (None, 64, 64, 512)  2048        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_55 (Add)                    (None, 64, 64, 512)  0           bn3d_branch2c[0][0]              \n",
            "                                                                 res3c_out[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "res3d_out (Activation)          (None, 64, 64, 512)  0           add_55[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 32, 32, 256)  131328      res3d_out[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNorm)       (None, 32, 32, 256)  1024        res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_136 (Activation)     (None, 32, 32, 256)  0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 32, 32, 256)  590080      activation_136[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNorm)       (None, 32, 32, 256)  1024        res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_137 (Activation)     (None, 32, 32, 256)  0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 32, 32, 1024) 263168      activation_137[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 32, 32, 1024) 525312      res3d_out[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNorm)       (None, 32, 32, 1024) 4096        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNorm)        (None, 32, 32, 1024) 4096        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_56 (Add)                    (None, 32, 32, 1024) 0           bn4a_branch2c[0][0]              \n",
            "                                                                 bn4a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res4a_out (Activation)          (None, 32, 32, 1024) 0           add_56[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 32, 32, 256)  262400      res4a_out[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNorm)       (None, 32, 32, 256)  1024        res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_138 (Activation)     (None, 32, 32, 256)  0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 32, 32, 256)  590080      activation_138[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNorm)       (None, 32, 32, 256)  1024        res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_139 (Activation)     (None, 32, 32, 256)  0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 32, 32, 1024) 263168      activation_139[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNorm)       (None, 32, 32, 1024) 4096        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_57 (Add)                    (None, 32, 32, 1024) 0           bn4b_branch2c[0][0]              \n",
            "                                                                 res4a_out[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "res4b_out (Activation)          (None, 32, 32, 1024) 0           add_57[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 32, 32, 256)  262400      res4b_out[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNorm)       (None, 32, 32, 256)  1024        res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_140 (Activation)     (None, 32, 32, 256)  0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 32, 32, 256)  590080      activation_140[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNorm)       (None, 32, 32, 256)  1024        res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_141 (Activation)     (None, 32, 32, 256)  0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 32, 32, 1024) 263168      activation_141[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNorm)       (None, 32, 32, 1024) 4096        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_58 (Add)                    (None, 32, 32, 1024) 0           bn4c_branch2c[0][0]              \n",
            "                                                                 res4b_out[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "res4c_out (Activation)          (None, 32, 32, 1024) 0           add_58[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 32, 32, 256)  262400      res4c_out[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNorm)       (None, 32, 32, 256)  1024        res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_142 (Activation)     (None, 32, 32, 256)  0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 32, 32, 256)  590080      activation_142[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNorm)       (None, 32, 32, 256)  1024        res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_143 (Activation)     (None, 32, 32, 256)  0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 32, 32, 1024) 263168      activation_143[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNorm)       (None, 32, 32, 1024) 4096        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_59 (Add)                    (None, 32, 32, 1024) 0           bn4d_branch2c[0][0]              \n",
            "                                                                 res4c_out[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "res4d_out (Activation)          (None, 32, 32, 1024) 0           add_59[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 32, 32, 256)  262400      res4d_out[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNorm)       (None, 32, 32, 256)  1024        res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_144 (Activation)     (None, 32, 32, 256)  0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 32, 32, 256)  590080      activation_144[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNorm)       (None, 32, 32, 256)  1024        res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_145 (Activation)     (None, 32, 32, 256)  0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 32, 32, 1024) 263168      activation_145[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNorm)       (None, 32, 32, 1024) 4096        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_60 (Add)                    (None, 32, 32, 1024) 0           bn4e_branch2c[0][0]              \n",
            "                                                                 res4d_out[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "res4e_out (Activation)          (None, 32, 32, 1024) 0           add_60[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 32, 32, 256)  262400      res4e_out[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNorm)       (None, 32, 32, 256)  1024        res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_146 (Activation)     (None, 32, 32, 256)  0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 32, 32, 256)  590080      activation_146[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNorm)       (None, 32, 32, 256)  1024        res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_147 (Activation)     (None, 32, 32, 256)  0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 32, 32, 1024) 263168      activation_147[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNorm)       (None, 32, 32, 1024) 4096        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_61 (Add)                    (None, 32, 32, 1024) 0           bn4f_branch2c[0][0]              \n",
            "                                                                 res4e_out[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "res4f_out (Activation)          (None, 32, 32, 1024) 0           add_61[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 16, 16, 512)  524800      res4f_out[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNorm)       (None, 16, 16, 512)  2048        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_148 (Activation)     (None, 16, 16, 512)  0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 16, 16, 512)  2359808     activation_148[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNorm)       (None, 16, 16, 512)  2048        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_149 (Activation)     (None, 16, 16, 512)  0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 16, 16, 2048) 1050624     activation_149[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 16, 16, 2048) 2099200     res4f_out[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNorm)       (None, 16, 16, 2048) 8192        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNorm)        (None, 16, 16, 2048) 8192        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_62 (Add)                    (None, 16, 16, 2048) 0           bn5a_branch2c[0][0]              \n",
            "                                                                 bn5a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res5a_out (Activation)          (None, 16, 16, 2048) 0           add_62[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 16, 16, 512)  1049088     res5a_out[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNorm)       (None, 16, 16, 512)  2048        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_150 (Activation)     (None, 16, 16, 512)  0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 16, 16, 512)  2359808     activation_150[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNorm)       (None, 16, 16, 512)  2048        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_151 (Activation)     (None, 16, 16, 512)  0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 16, 16, 2048) 1050624     activation_151[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNorm)       (None, 16, 16, 2048) 8192        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_63 (Add)                    (None, 16, 16, 2048) 0           bn5b_branch2c[0][0]              \n",
            "                                                                 res5a_out[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "res5b_out (Activation)          (None, 16, 16, 2048) 0           add_63[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 16, 16, 512)  1049088     res5b_out[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNorm)       (None, 16, 16, 512)  2048        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_152 (Activation)     (None, 16, 16, 512)  0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 16, 16, 512)  2359808     activation_152[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNorm)       (None, 16, 16, 512)  2048        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_153 (Activation)     (None, 16, 16, 512)  0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 16, 16, 2048) 1050624     activation_153[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNorm)       (None, 16, 16, 2048) 8192        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_64 (Add)                    (None, 16, 16, 2048) 0           bn5c_branch2c[0][0]              \n",
            "                                                                 res5b_out[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "res5c_out (Activation)          (None, 16, 16, 2048) 0           add_64[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "fpn_c5p5 (Conv2D)               (None, 16, 16, 256)  524544      res5c_out[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "fpn_p5upsampled (UpSampling2D)  (None, 32, 32, 256)  0           fpn_c5p5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "fpn_c4p4 (Conv2D)               (None, 32, 32, 256)  262400      res4f_out[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "fpn_p4add (Add)                 (None, 32, 32, 256)  0           fpn_p5upsampled[0][0]            \n",
            "                                                                 fpn_c4p4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "fpn_p4upsampled (UpSampling2D)  (None, 64, 64, 256)  0           fpn_p4add[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "fpn_c3p3 (Conv2D)               (None, 64, 64, 256)  131328      res3d_out[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "fpn_p3add (Add)                 (None, 64, 64, 256)  0           fpn_p4upsampled[0][0]            \n",
            "                                                                 fpn_c3p3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "fpn_p3upsampled (UpSampling2D)  (None, 128, 128, 256 0           fpn_p3add[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "fpn_c2p2 (Conv2D)               (None, 128, 128, 256 65792       res2c_out[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "fpn_p2add (Add)                 (None, 128, 128, 256 0           fpn_p3upsampled[0][0]            \n",
            "                                                                 fpn_c2p2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "fpn_p5 (Conv2D)                 (None, 16, 16, 256)  590080      fpn_c5p5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "fpn_p2 (Conv2D)                 (None, 128, 128, 256 590080      fpn_p2add[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "fpn_p3 (Conv2D)                 (None, 64, 64, 256)  590080      fpn_p3add[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "fpn_p4 (Conv2D)                 (None, 32, 32, 256)  590080      fpn_p4add[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "fpn_p6 (MaxPooling2D)           (None, 8, 8, 256)    0           fpn_p5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "rpn_model (Model)               [(None, None, 2), (N 1189394     fpn_p2[0][0]                     \n",
            "                                                                 fpn_p3[0][0]                     \n",
            "                                                                 fpn_p4[0][0]                     \n",
            "                                                                 fpn_p5[0][0]                     \n",
            "                                                                 fpn_p6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "rpn_class (Concatenate)         (None, None, 2)      0           rpn_model[1][1]                  \n",
            "                                                                 rpn_model[2][1]                  \n",
            "                                                                 rpn_model[3][1]                  \n",
            "                                                                 rpn_model[4][1]                  \n",
            "                                                                 rpn_model[5][1]                  \n",
            "__________________________________________________________________________________________________\n",
            "rpn_bbox (Concatenate)          (None, None, 4)      0           rpn_model[1][2]                  \n",
            "                                                                 rpn_model[2][2]                  \n",
            "                                                                 rpn_model[3][2]                  \n",
            "                                                                 rpn_model[4][2]                  \n",
            "                                                                 rpn_model[5][2]                  \n",
            "__________________________________________________________________________________________________\n",
            "input_gt_boxes (InputLayer)     (None, None, 4)      0                                            \n",
            "__________________________________________________________________________________________________\n",
            "ROI (ProposalLayer)             (None, 2000, 4)      0           rpn_class[0][0]                  \n",
            "                                                                 rpn_bbox[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "input_gt_class_ids (InputLayer) (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lambda_11 (Lambda)              (None, None, 4)      0           input_gt_boxes[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "input_gt_masks (InputLayer)     (None, 56, 56, None) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "proposal_targets (DetectionTarg [(None, 600, 4), (No 0           ROI[0][0]                        \n",
            "                                                                 input_gt_class_ids[0][0]         \n",
            "                                                                 lambda_11[0][0]                  \n",
            "                                                                 input_gt_masks[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "roi_align_mask (PyramidROIAlign (None, 600, 14, 14,  0           proposal_targets[0][0]           \n",
            "                                                                 fpn_p2[0][0]                     \n",
            "                                                                 fpn_p3[0][0]                     \n",
            "                                                                 fpn_p4[0][0]                     \n",
            "                                                                 fpn_p5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mrcnn_mask_conv1 (TimeDistribut (None, 600, 14, 14,  590080      roi_align_mask[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "mrcnn_mask_bn1 (TimeDistributed (None, 600, 14, 14,  1024        mrcnn_mask_conv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_157 (Activation)     (None, 600, 14, 14,  0           mrcnn_mask_bn1[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "mrcnn_mask_conv2 (TimeDistribut (None, 600, 14, 14,  590080      activation_157[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "roi_align_classifier (PyramidRO (None, 600, 7, 7, 25 0           proposal_targets[0][0]           \n",
            "                                                                 fpn_p2[0][0]                     \n",
            "                                                                 fpn_p3[0][0]                     \n",
            "                                                                 fpn_p4[0][0]                     \n",
            "                                                                 fpn_p5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mrcnn_mask_bn2 (TimeDistributed (None, 600, 14, 14,  1024        mrcnn_mask_conv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "mrcnn_class_conv1 (TimeDistribu (None, 600, 1, 1, 10 12846080    roi_align_classifier[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_158 (Activation)     (None, 600, 14, 14,  0           mrcnn_mask_bn2[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "mrcnn_class_bn1 (TimeDistribute (None, 600, 1, 1, 10 4096        mrcnn_class_conv1[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "mrcnn_mask_conv3 (TimeDistribut (None, 600, 14, 14,  590080      activation_158[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_154 (Activation)     (None, 600, 1, 1, 10 0           mrcnn_class_bn1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mrcnn_mask_bn3 (TimeDistributed (None, 600, 14, 14,  1024        mrcnn_mask_conv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "mrcnn_class_conv2 (TimeDistribu (None, 600, 1, 1, 10 1049600     activation_154[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_159 (Activation)     (None, 600, 14, 14,  0           mrcnn_mask_bn3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "mrcnn_class_bn2 (TimeDistribute (None, 600, 1, 1, 10 4096        mrcnn_class_conv2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "mrcnn_mask_conv4 (TimeDistribut (None, 600, 14, 14,  590080      activation_159[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_155 (Activation)     (None, 600, 1, 1, 10 0           mrcnn_class_bn2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mrcnn_mask_bn4 (TimeDistributed (None, 600, 14, 14,  1024        mrcnn_mask_conv4[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "pool_squeeze (Lambda)           (None, 600, 1024)    0           activation_155[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_160 (Activation)     (None, 600, 14, 14,  0           mrcnn_mask_bn4[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "mrcnn_bbox_fc (TimeDistributed) (None, 600, 8)       8200        pool_squeeze[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "mrcnn_mask_deconv (TimeDistribu (None, 600, 28, 28,  262400      activation_160[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "input_image_meta (InputLayer)   (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "rpn_class_logits (Concatenate)  (None, None, 2)      0           rpn_model[1][0]                  \n",
            "                                                                 rpn_model[2][0]                  \n",
            "                                                                 rpn_model[3][0]                  \n",
            "                                                                 rpn_model[4][0]                  \n",
            "                                                                 rpn_model[5][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "mrcnn_class_logits (TimeDistrib (None, 600, 2)       2050        pool_squeeze[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "mrcnn_bbox (Reshape)            (None, 600, 2, 4)    0           mrcnn_bbox_fc[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mrcnn_mask (TimeDistributed)    (None, 600, 28, 28,  514         mrcnn_mask_deconv[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "input_rpn_match (InputLayer)    (None, None, 1)      0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_rpn_bbox (InputLayer)     (None, None, 4)      0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lambda_14 (Lambda)              [(None,), (None, Non 0           input_image_meta[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "mrcnn_class (TimeDistributed)   (None, 600, 2)       0           mrcnn_class_logits[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "output_rois (Lambda)            (None, 600, 4)       0           proposal_targets[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "rpn_class_loss (Lambda)         ()                   0           input_rpn_match[0][0]            \n",
            "                                                                 rpn_class_logits[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "rpn_bbox_loss (Lambda)          ()                   0           input_rpn_bbox[0][0]             \n",
            "                                                                 input_rpn_match[0][0]            \n",
            "                                                                 rpn_bbox[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "mrcnn_class_loss (Lambda)       ()                   0           proposal_targets[0][1]           \n",
            "                                                                 mrcnn_class_logits[0][0]         \n",
            "                                                                 lambda_14[0][3]                  \n",
            "__________________________________________________________________________________________________\n",
            "mrcnn_bbox_loss (Lambda)        (1, 1)               0           proposal_targets[0][2]           \n",
            "                                                                 proposal_targets[0][1]           \n",
            "                                                                 mrcnn_bbox[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mrcnn_mask_loss (Lambda)        (1, 1)               0           proposal_targets[0][3]           \n",
            "                                                                 proposal_targets[0][1]           \n",
            "                                                                 mrcnn_mask[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 44,662,942\n",
            "Trainable params: 44,603,678\n",
            "Non-trainable params: 59,264\n",
            "__________________________________________________________________________________________________\n",
            "\n",
            "Starting at epoch 31. LR=0.0001\n",
            "\n",
            "Checkpoint Path: /content/logs/bowl20180403T0311/mask_rcnn_bowl_{epoch:04d}.h5\n",
            "Selecting layers to train\n",
            "conv1                  (Conv2D)\n",
            "bn_conv1               (BatchNorm)\n",
            "res2a_branch2a         (Conv2D)\n",
            "bn2a_branch2a          (BatchNorm)\n",
            "res2a_branch2b         (Conv2D)\n",
            "bn2a_branch2b          (BatchNorm)\n",
            "res2a_branch2c         (Conv2D)\n",
            "res2a_branch1          (Conv2D)\n",
            "bn2a_branch2c          (BatchNorm)\n",
            "bn2a_branch1           (BatchNorm)\n",
            "res2b_branch2a         (Conv2D)\n",
            "bn2b_branch2a          (BatchNorm)\n",
            "res2b_branch2b         (Conv2D)\n",
            "bn2b_branch2b          (BatchNorm)\n",
            "res2b_branch2c         (Conv2D)\n",
            "bn2b_branch2c          (BatchNorm)\n",
            "res2c_branch2a         (Conv2D)\n",
            "bn2c_branch2a          (BatchNorm)\n",
            "res2c_branch2b         (Conv2D)\n",
            "bn2c_branch2b          (BatchNorm)\n",
            "res2c_branch2c         (Conv2D)\n",
            "bn2c_branch2c          (BatchNorm)\n",
            "res3a_branch2a         (Conv2D)\n",
            "bn3a_branch2a          (BatchNorm)\n",
            "res3a_branch2b         (Conv2D)\n",
            "bn3a_branch2b          (BatchNorm)\n",
            "res3a_branch2c         (Conv2D)\n",
            "res3a_branch1          (Conv2D)\n",
            "bn3a_branch2c          (BatchNorm)\n",
            "bn3a_branch1           (BatchNorm)\n",
            "res3b_branch2a         (Conv2D)\n",
            "bn3b_branch2a          (BatchNorm)\n",
            "res3b_branch2b         (Conv2D)\n",
            "bn3b_branch2b          (BatchNorm)\n",
            "res3b_branch2c         (Conv2D)\n",
            "bn3b_branch2c          (BatchNorm)\n",
            "res3c_branch2a         (Conv2D)\n",
            "bn3c_branch2a          (BatchNorm)\n",
            "res3c_branch2b         (Conv2D)\n",
            "bn3c_branch2b          (BatchNorm)\n",
            "res3c_branch2c         (Conv2D)\n",
            "bn3c_branch2c          (BatchNorm)\n",
            "res3d_branch2a         (Conv2D)\n",
            "bn3d_branch2a          (BatchNorm)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "res3d_branch2b         (Conv2D)\n",
            "bn3d_branch2b          (BatchNorm)\n",
            "res3d_branch2c         (Conv2D)\n",
            "bn3d_branch2c          (BatchNorm)\n",
            "res4a_branch2a         (Conv2D)\n",
            "bn4a_branch2a          (BatchNorm)\n",
            "res4a_branch2b         (Conv2D)\n",
            "bn4a_branch2b          (BatchNorm)\n",
            "res4a_branch2c         (Conv2D)\n",
            "res4a_branch1          (Conv2D)\n",
            "bn4a_branch2c          (BatchNorm)\n",
            "bn4a_branch1           (BatchNorm)\n",
            "res4b_branch2a         (Conv2D)\n",
            "bn4b_branch2a          (BatchNorm)\n",
            "res4b_branch2b         (Conv2D)\n",
            "bn4b_branch2b          (BatchNorm)\n",
            "res4b_branch2c         (Conv2D)\n",
            "bn4b_branch2c          (BatchNorm)\n",
            "res4c_branch2a         (Conv2D)\n",
            "bn4c_branch2a          (BatchNorm)\n",
            "res4c_branch2b         (Conv2D)\n",
            "bn4c_branch2b          (BatchNorm)\n",
            "res4c_branch2c         (Conv2D)\n",
            "bn4c_branch2c          (BatchNorm)\n",
            "res4d_branch2a         (Conv2D)\n",
            "bn4d_branch2a          (BatchNorm)\n",
            "res4d_branch2b         (Conv2D)\n",
            "bn4d_branch2b          (BatchNorm)\n",
            "res4d_branch2c         (Conv2D)\n",
            "bn4d_branch2c          (BatchNorm)\n",
            "res4e_branch2a         (Conv2D)\n",
            "bn4e_branch2a          (BatchNorm)\n",
            "res4e_branch2b         (Conv2D)\n",
            "bn4e_branch2b          (BatchNorm)\n",
            "res4e_branch2c         (Conv2D)\n",
            "bn4e_branch2c          (BatchNorm)\n",
            "res4f_branch2a         (Conv2D)\n",
            "bn4f_branch2a          (BatchNorm)\n",
            "res4f_branch2b         (Conv2D)\n",
            "bn4f_branch2b          (BatchNorm)\n",
            "res4f_branch2c         (Conv2D)\n",
            "bn4f_branch2c          (BatchNorm)\n",
            "res5a_branch2a         (Conv2D)\n",
            "bn5a_branch2a          (BatchNorm)\n",
            "res5a_branch2b         (Conv2D)\n",
            "bn5a_branch2b          (BatchNorm)\n",
            "res5a_branch2c         (Conv2D)\n",
            "res5a_branch1          (Conv2D)\n",
            "bn5a_branch2c          (BatchNorm)\n",
            "bn5a_branch1           (BatchNorm)\n",
            "res5b_branch2a         (Conv2D)\n",
            "bn5b_branch2a          (BatchNorm)\n",
            "res5b_branch2b         (Conv2D)\n",
            "bn5b_branch2b          (BatchNorm)\n",
            "res5b_branch2c         (Conv2D)\n",
            "bn5b_branch2c          (BatchNorm)\n",
            "res5c_branch2a         (Conv2D)\n",
            "bn5c_branch2a          (BatchNorm)\n",
            "res5c_branch2b         (Conv2D)\n",
            "bn5c_branch2b          (BatchNorm)\n",
            "res5c_branch2c         (Conv2D)\n",
            "bn5c_branch2c          (BatchNorm)\n",
            "fpn_c5p5               (Conv2D)\n",
            "fpn_c4p4               (Conv2D)\n",
            "fpn_c3p3               (Conv2D)\n",
            "fpn_c2p2               (Conv2D)\n",
            "fpn_p5                 (Conv2D)\n",
            "fpn_p2                 (Conv2D)\n",
            "fpn_p3                 (Conv2D)\n",
            "fpn_p4                 (Conv2D)\n",
            "In model:  rpn_model\n",
            "    rpn_conv_shared        (Conv2D)\n",
            "    rpn_class_raw          (Conv2D)\n",
            "    rpn_bbox_pred          (Conv2D)\n",
            "mrcnn_mask_conv1       (TimeDistributed)\n",
            "mrcnn_mask_bn1         (TimeDistributed)\n",
            "mrcnn_mask_conv2       (TimeDistributed)\n",
            "mrcnn_mask_bn2         (TimeDistributed)\n",
            "mrcnn_class_conv1      (TimeDistributed)\n",
            "mrcnn_class_bn1        (TimeDistributed)\n",
            "mrcnn_mask_conv3       (TimeDistributed)\n",
            "mrcnn_mask_bn3         (TimeDistributed)\n",
            "mrcnn_class_conv2      (TimeDistributed)\n",
            "mrcnn_class_bn2        (TimeDistributed)\n",
            "mrcnn_mask_conv4       (TimeDistributed)\n",
            "mrcnn_mask_bn4         (TimeDistributed)\n",
            "mrcnn_bbox_fc          (TimeDistributed)\n",
            "mrcnn_mask_deconv      (TimeDistributed)\n",
            "mrcnn_class_logits     (TimeDistributed)\n",
            "mrcnn_mask             (TimeDistributed)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/scipy/ndimage/interpolation.py:600: UserWarning: From scipy 0.13.0, the output shape of zoom() is calculated with round() instead of int() - for these inputs the size of the returned array has changed.\n",
            "  \"the returned array has changed.\", UserWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py:98: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 32/35\n",
            "332/332 [==============================] - 853s 3s/step - loss: 0.8322 - rpn_class_loss: 0.0329 - rpn_bbox_loss: 0.2925 - mrcnn_class_loss: 0.1226 - mrcnn_bbox_loss: 0.1530 - mrcnn_mask_loss: 0.2312 - val_loss: 0.7368 - val_rpn_class_loss: 0.0245 - val_rpn_bbox_loss: 0.1921 - val_mrcnn_class_loss: 0.1234 - val_mrcnn_bbox_loss: 0.1515 - val_mrcnn_mask_loss: 0.2453\n",
            "Epoch 33/35\n",
            " 52/332 [===>..........................] - ETA: 11:38 - loss: 0.8181 - rpn_class_loss: 0.0298 - rpn_bbox_loss: 0.2885 - mrcnn_class_loss: 0.1178 - mrcnn_bbox_loss: 0.1510 - mrcnn_mask_loss: 0.2310332/332 [==============================] - 831s 3s/step - loss: 0.8286 - rpn_class_loss: 0.0317 - rpn_bbox_loss: 0.2898 - mrcnn_class_loss: 0.1224 - mrcnn_bbox_loss: 0.1534 - mrcnn_mask_loss: 0.2313 - val_loss: 0.7466 - val_rpn_class_loss: 0.0274 - val_rpn_bbox_loss: 0.1884 - val_mrcnn_class_loss: 0.1236 - val_mrcnn_bbox_loss: 0.1554 - val_mrcnn_mask_loss: 0.2517\n",
            "Epoch 34/35\n",
            " 77/332 [=====>........................] - ETA: 10:34 - loss: 0.7900 - rpn_class_loss: 0.0294 - rpn_bbox_loss: 0.2774 - mrcnn_class_loss: 0.1168 - mrcnn_bbox_loss: 0.1443 - mrcnn_mask_loss: 0.2221332/332 [==============================] - 833s 3s/step - loss: 0.8184 - rpn_class_loss: 0.0318 - rpn_bbox_loss: 0.2858 - mrcnn_class_loss: 0.1211 - mrcnn_bbox_loss: 0.1507 - mrcnn_mask_loss: 0.2290 - val_loss: 0.7369 - val_rpn_class_loss: 0.0241 - val_rpn_bbox_loss: 0.1883 - val_mrcnn_class_loss: 0.1431 - val_mrcnn_bbox_loss: 0.1379 - val_mrcnn_mask_loss: 0.2435\n",
            "Epoch 35/35\n",
            " 86/332 [======>.......................] - ETA: 10:15 - loss: 0.7999 - rpn_class_loss: 0.0327 - rpn_bbox_loss: 0.2761 - mrcnn_class_loss: 0.1202 - mrcnn_bbox_loss: 0.1453 - mrcnn_mask_loss: 0.2256332/332 [==============================] - 832s 3s/step - loss: 0.8105 - rpn_class_loss: 0.0309 - rpn_bbox_loss: 0.2813 - mrcnn_class_loss: 0.1200 - mrcnn_bbox_loss: 0.1498 - mrcnn_mask_loss: 0.2286 - val_loss: 0.7454 - val_rpn_class_loss: 0.0270 - val_rpn_bbox_loss: 0.1822 - val_mrcnn_class_loss: 0.1376 - val_mrcnn_bbox_loss: 0.1486 - val_mrcnn_mask_loss: 0.2500\n",
            "logs/bowl20180403T0311/mask_rcnn_bowl_0035.h5\n",
            "Loading weights from  /content/logs/bowl20180403T0311/mask_rcnn_bowl_0035.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|| 65/65 [00:32<00:00,  1.98it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-b756c37b0cc4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mdl_wts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m   \u001b[0mlocal_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-90e3bfe468bf>\u001b[0m in \u001b[0;36mlocal_download\u001b[0;34m(fn)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlocal_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m   \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m   \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    170\u001b[0m       \u001b[0;34m'port'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m       \u001b[0;34m'path'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m       \u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m   })\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     84\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m     85\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: TypeError: Failed to fetch"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "6x5Wt5XYpBqn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 6 of 6:Submit predictions to Kaggle directly "
      ]
    },
    {
      "metadata": {
        "id": "nYUfkXwX9eZZ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c4c6fc81-e32f-4b27-bb97-115d8f50f6fc",
        "executionInfo": {
          "elapsed": 4634,
          "status": "ok",
          "timestamp": 1522816190079,
          "user": {
            "displayName": "Aftab Khan",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "115745872669652090393"
          },
          "user_tz": 300
        }
      },
      "cell_type": "code",
      "source": [
        "!kaggle competitions submit -c data-science-bowl-2018 -f submission.csv -m \"With 20 epochs COCO weights\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Successfully submitted to 2018 Data Science Bowl "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "c28QOwrIx_tj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Retrieving a trained weights file from Google Drive\n",
        "After after 5 epochs the weights file will be stored on your Google Drive. For example, after 25 epochs, a file named 'mask_rcnn_bowl_0025.h5' (approx 178MB) will be stored on the Google Drive.\n",
        "\n",
        "To retrieve this file:\n",
        "- go to Google Drive and right click on the file\n",
        "- choose 'Get shareable link'. \n",
        "- A link will be provided which looks like: 'https://drive.google.com/open?id=1-LL7F3NWcIiDvxFdjncRFj_z5B7i0Aln'\n",
        "- Copy the id part e.g '1-LL7F3NWcIiDvxFdjncRFj_z5B7i0Aln'\n",
        "- Paste in the cell below for 'fileid='\n",
        "- Run the cell\n",
        "- It will upload the file in the destination folder. The destination folder is where the RCNN looks for the last weight file.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "PkZe54RsbG4F",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "e8be8bf7-7f71-4774-a538-4f8e768043fe",
        "executionInfo": {
          "elapsed": 1965,
          "status": "ok",
          "timestamp": 1522808385250,
          "user": {
            "displayName": "Aftab Khan",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "115745872669652090393"
          },
          "user_tz": 300
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install googledrivedownloader\n",
        "\n",
        "## Get weight file\n",
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "\n",
        "fileid='1-LL7F3NWcIiDvxFdjncRFj_z5B7i0Aln'  # example file id. To get the file id see instructions above\n",
        "destpath='./logs/bowl20180403T0311/'        # this should work irrespective of the date\n",
        "\n",
        "os.makedirs(os.path.dirname(destpath), exist_ok=True)\n",
        "\n",
        "gdd.download_file_from_google_drive(file_id=fileid,\n",
        "                                    dest_path=destpath,\n",
        "                                    unzip=True)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 1r8VAfPBc3jION6DY40zut-Qsh3Hbljo4 into ./logs/bowl20180403T0311/mask_rcnn_bowl_0025.h5... Done.\n",
            "Unzipping..."
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/google_drive_downloader/google_drive_downloader.py:73: UserWarning: Ignoring `unzip` since \"1r8VAfPBc3jION6DY40zut-Qsh3Hbljo4\" does not look like a valid zip file\n",
            "  warnings.warn('Ignoring `unzip` since \"{}\" does not look like a valid zip file'.format(file_id))\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}